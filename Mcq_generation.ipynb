{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0foQIjG5Ante",
        "outputId": "f09751dd-5a77-498b-b465-92b0b6f111c4"
      },
      "source": [
        "!pip install gensim\n",
        "!pip install git+https://github.com/boudinfl/pke.git\n",
        "!pip install bert-extractive-summarizer --upgrade --force-reinstall\n",
        "!pip install spacy==2.1.3 --upgrade --force-reinstall\n",
        "!python -m spacy download en\n",
        "!pip install flashtext\n",
        "!pip install -U nltk\n",
        "!pip install neuralcoref\n",
        "!pip install sentencepiece\n",
        "!pip install -U pywsd\n",
        "!pip install wn==0.0.22\n",
        "!pip install tika\n",
        "!pip install PyMuPDF\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Collecting git+https://github.com/boudinfl/pke.git\n",
            "  Cloning https://github.com/boudinfl/pke.git to /tmp/pip-req-build-w8shzncx\n",
            "  Running command git clone -q https://github.com/boudinfl/pke.git /tmp/pip-req-build-w8shzncx\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from pke==1.8.1) (3.2.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from pke==1.8.1) (2.6.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pke==1.8.1) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pke==1.8.1) (1.4.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (from pke==1.8.1) (2.2.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pke==1.8.1) (1.15.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pke==1.8.1) (0.0)\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.2-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 8.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pke==1.8.1) (0.16.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pke==1.8.1) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->pke==1.8.1) (0.22.2.post1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (2.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (57.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (3.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (4.62.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (0.8.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->pke==1.8.1) (4.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy->pke==1.8.1) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy->pke==1.8.1) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (1.24.3)\n",
            "Building wheels for collected packages: pke\n",
            "  Building wheel for pke (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pke: filename=pke-1.8.1-py3-none-any.whl size=8764035 sha256=b214c4e2c36f4756eacaef04ee2385630ecfe6893e79370c5f523ae99d340e72\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9bu9ymi3/wheels/fa/b3/09/612ee93bf3ee4164bcd5783e742942cdfc892a86039d3e0a33\n",
            "Successfully built pke\n",
            "Installing collected packages: unidecode, pke\n",
            "Successfully installed pke-1.8.1 unidecode-1.3.2\n",
            "Collecting bert-extractive-summarizer\n",
            "  Downloading bert_extractive_summarizer-0.8.1-py3-none-any.whl (19 kB)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.1.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 7.1 MB/s \n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.11.2-py3-none-any.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 43.6 MB/s \n",
            "\u001b[?25hCollecting scikit-learn\n",
            "  Downloading scikit_learn-1.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.1 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting numpy>=1.14.6\n",
            "  Downloading numpy-1.21.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 195 kB/s \n",
            "\u001b[?25hCollecting scipy>=1.1.0\n",
            "  Downloading scipy-1.7.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (28.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 28.5 MB 49 kB/s \n",
            "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.0.0-py3-none-any.whl (14 kB)\n",
            "Collecting joblib>=0.11\n",
            "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
            "\u001b[K     |████████████████████████████████| 303 kB 57.1 MB/s \n",
            "\u001b[?25hCollecting requests<3.0.0,>=2.13.0\n",
            "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 740 kB/s \n",
            "\u001b[?25hCollecting blis<0.8.0,>=0.4.0\n",
            "  Downloading blis-0.7.4-cp37-cp37m-manylinux2014_x86_64.whl (9.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.8 MB 128 kB/s \n",
            "\u001b[?25hCollecting spacy-legacy<3.1.0,>=3.0.8\n",
            "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
            "Collecting wasabi<1.1.0,>=0.8.1\n",
            "  Downloading wasabi-0.8.2-py3-none-any.whl (23 kB)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-58.2.0-py3-none-any.whl (946 kB)\n",
            "\u001b[K     |████████████████████████████████| 946 kB 44.9 MB/s \n",
            "\u001b[?25hCollecting cymem<2.1.0,>=2.0.2\n",
            "  Downloading cymem-2.0.5-cp37-cp37m-manylinux2014_x86_64.whl (35 kB)\n",
            "Collecting typing-extensions<4.0.0.0,>=3.7.4\n",
            "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
            "Collecting murmurhash<1.1.0,>=0.28.0\n",
            "  Downloading murmurhash-1.0.5-cp37-cp37m-manylinux2014_x86_64.whl (20 kB)\n",
            "Collecting pathy>=0.3.5\n",
            "  Downloading pathy-0.6.0-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.3 MB/s \n",
            "\u001b[?25hCollecting thinc<8.1.0,>=8.0.9\n",
            "  Downloading thinc-8.0.10-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (623 kB)\n",
            "\u001b[K     |████████████████████████████████| 623 kB 68.8 MB/s \n",
            "\u001b[?25hCollecting preshed<3.1.0,>=3.0.2\n",
            "  Downloading preshed-3.0.5-cp37-cp37m-manylinux2014_x86_64.whl (126 kB)\n",
            "\u001b[K     |████████████████████████████████| 126 kB 74.9 MB/s \n",
            "\u001b[?25hCollecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 46.0 MB/s \n",
            "\u001b[?25hCollecting typer<0.5.0,>=0.3.0\n",
            "  Downloading typer-0.4.0-py3-none-any.whl (27 kB)\n",
            "Collecting srsly<3.0.0,>=2.4.1\n",
            "  Downloading srsly-2.4.1-cp37-cp37m-manylinux2014_x86_64.whl (456 kB)\n",
            "\u001b[K     |████████████████████████████████| 456 kB 65.6 MB/s \n",
            "\u001b[?25hCollecting tqdm<5.0.0,>=4.38.0\n",
            "  Downloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 4.9 MB/s \n",
            "\u001b[?25hCollecting packaging>=20.0\n",
            "  Downloading packaging-21.0-py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 4.8 MB/s \n",
            "\u001b[?25hCollecting jinja2\n",
            "  Downloading Jinja2-3.0.2-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 69.8 MB/s \n",
            "\u001b[?25hCollecting catalogue<2.1.0,>=2.0.6\n",
            "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
            "Collecting zipp>=0.5\n",
            "  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\n",
            "Collecting pyparsing>=2.0.2\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.8 MB/s \n",
            "\u001b[?25hCollecting smart-open<6.0.0,>=5.0.0\n",
            "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.0 MB/s \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 58.8 MB/s \n",
            "\u001b[?25hCollecting idna<4,>=2.5\n",
            "  Downloading idna-3.2-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 6.2 MB/s \n",
            "\u001b[?25hCollecting charset-normalizer~=2.0.0\n",
            "  Downloading charset_normalizer-2.0.6-py3-none-any.whl (37 kB)\n",
            "Collecting certifi>=2017.4.17\n",
            "  Downloading certifi-2021.5.30-py2.py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 42.4 MB/s \n",
            "\u001b[?25hCollecting click<9.0.0,>=7.1.1\n",
            "  Downloading click-8.0.1-py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 6.5 MB/s \n",
            "\u001b[?25hCollecting importlib-metadata\n",
            "  Downloading importlib_metadata-4.8.1-py3-none-any.whl (17 kB)\n",
            "Collecting MarkupSafe>=2.0\n",
            "  Downloading MarkupSafe-2.0.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (31 kB)\n",
            "Collecting regex!=2019.12.17\n",
            "  Downloading regex-2021.9.30-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (747 kB)\n",
            "\u001b[K     |████████████████████████████████| 747 kB 53.1 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 39.1 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 49.8 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 44.6 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub>=0.0.17\n",
            "  Downloading huggingface_hub-0.0.18-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.7 MB/s \n",
            "\u001b[?25hCollecting filelock\n",
            "  Downloading filelock-3.3.0-py3-none-any.whl (9.7 kB)\n",
            "Collecting ruamel.yaml==0.17.16\n",
            "  Downloading ruamel.yaml-0.17.16-py3-none-any.whl (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 72.7 MB/s \n",
            "\u001b[?25hCollecting ruamel.yaml.clib>=0.1.2\n",
            "  Downloading ruamel.yaml.clib-0.2.6-cp37-cp37m-manylinux1_x86_64.whl (546 kB)\n",
            "\u001b[K     |████████████████████████████████| 546 kB 72.4 MB/s \n",
            "\u001b[?25hCollecting six\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: zipp, typing-extensions, importlib-metadata, urllib3, ruamel.yaml.clib, pyparsing, numpy, murmurhash, idna, cymem, click, charset-normalizer, certifi, catalogue, wasabi, typer, tqdm, srsly, smart-open, six, setuptools, ruamel.yaml, requests, regex, pydantic, preshed, packaging, MarkupSafe, joblib, filelock, blis, tokenizers, threadpoolctl, thinc, spacy-legacy, scipy, sacremoses, pyyaml, pathy, jinja2, huggingface-hub, transformers, spacy, scikit-learn, bert-extractive-summarizer\n",
            "  Attempting uninstall: zipp\n",
            "    Found existing installation: zipp 3.6.0\n",
            "    Uninstalling zipp-3.6.0:\n",
            "      Successfully uninstalled zipp-3.6.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 3.7.4.3\n",
            "    Uninstalling typing-extensions-3.7.4.3:\n",
            "      Successfully uninstalled typing-extensions-3.7.4.3\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.8.1\n",
            "    Uninstalling importlib-metadata-4.8.1:\n",
            "      Successfully uninstalled importlib-metadata-4.8.1\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 2.4.7\n",
            "    Uninstalling pyparsing-2.4.7:\n",
            "      Successfully uninstalled pyparsing-2.4.7\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: murmurhash\n",
            "    Found existing installation: murmurhash 1.0.5\n",
            "    Uninstalling murmurhash-1.0.5:\n",
            "      Successfully uninstalled murmurhash-1.0.5\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Attempting uninstall: cymem\n",
            "    Found existing installation: cymem 2.0.5\n",
            "    Uninstalling cymem-2.0.5:\n",
            "      Successfully uninstalled cymem-2.0.5\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 2.0.6\n",
            "    Uninstalling charset-normalizer-2.0.6:\n",
            "      Successfully uninstalled charset-normalizer-2.0.6\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2021.5.30\n",
            "    Uninstalling certifi-2021.5.30:\n",
            "      Successfully uninstalled certifi-2021.5.30\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Attempting uninstall: wasabi\n",
            "    Found existing installation: wasabi 0.8.2\n",
            "    Uninstalling wasabi-0.8.2:\n",
            "      Successfully uninstalled wasabi-0.8.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.62.3\n",
            "    Uninstalling tqdm-4.62.3:\n",
            "      Successfully uninstalled tqdm-4.62.3\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Attempting uninstall: smart-open\n",
            "    Found existing installation: smart-open 5.2.1\n",
            "    Uninstalling smart-open-5.2.1:\n",
            "      Successfully uninstalled smart-open-5.2.1\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.4.0\n",
            "    Uninstalling setuptools-57.4.0:\n",
            "      Successfully uninstalled setuptools-57.4.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Attempting uninstall: preshed\n",
            "    Found existing installation: preshed 3.0.5\n",
            "    Uninstalling preshed-3.0.5:\n",
            "      Successfully uninstalled preshed-3.0.5\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 21.0\n",
            "    Uninstalling packaging-21.0:\n",
            "      Successfully uninstalled packaging-21.0\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.0.1\n",
            "    Uninstalling MarkupSafe-2.0.1:\n",
            "      Successfully uninstalled MarkupSafe-2.0.1\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.0.1\n",
            "    Uninstalling joblib-1.0.1:\n",
            "      Successfully uninstalled joblib-1.0.1\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.2.0\n",
            "    Uninstalling filelock-3.2.0:\n",
            "      Successfully uninstalled filelock-3.2.0\n",
            "  Attempting uninstall: blis\n",
            "    Found existing installation: blis 0.4.1\n",
            "    Uninstalling blis-0.4.1:\n",
            "      Successfully uninstalled blis-0.4.1\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 2.11.3\n",
            "    Uninstalling Jinja2-2.11.3:\n",
            "      Successfully uninstalled Jinja2-2.11.3\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.6.0 requires numpy~=1.19.2, but you have numpy 1.21.2 which is incompatible.\n",
            "tensorflow 2.6.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "tensorflow 2.6.0 requires typing-extensions~=3.7.4, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "streamlit 1.0.0 requires click<8.0,>=7.0, but you have click 8.0.1 which is incompatible.\n",
            "google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.4.1 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.28.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "flask 1.1.4 requires click<8.0,>=5.1, but you have click 8.0.1 which is incompatible.\n",
            "flask 1.1.4 requires Jinja2<3.0,>=2.10.1, but you have jinja2 3.0.2 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed MarkupSafe-2.0.1 bert-extractive-summarizer-0.8.1 blis-0.7.4 catalogue-2.0.6 certifi-2021.5.30 charset-normalizer-2.0.6 click-8.0.1 cymem-2.0.5 filelock-3.3.0 huggingface-hub-0.0.18 idna-3.2 importlib-metadata-4.8.1 jinja2-3.0.2 joblib-1.0.1 murmurhash-1.0.5 numpy-1.21.2 packaging-21.0 pathy-0.6.0 preshed-3.0.5 pydantic-1.8.2 pyparsing-2.4.7 pyyaml-5.4.1 regex-2021.9.30 requests-2.26.0 ruamel.yaml-0.17.16 ruamel.yaml.clib-0.2.6 sacremoses-0.0.46 scikit-learn-1.0 scipy-1.7.1 setuptools-58.2.0 six-1.16.0 smart-open-5.2.1 spacy-3.1.3 spacy-legacy-3.0.8 srsly-2.4.1 thinc-8.0.10 threadpoolctl-3.0.0 tokenizers-0.10.3 tqdm-4.62.3 transformers-4.11.2 typer-0.4.0 typing-extensions-3.10.0.2 urllib3-1.26.7 wasabi-0.8.2 zipp-3.6.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "idna",
                  "joblib",
                  "numpy",
                  "pkg_resources",
                  "pyparsing",
                  "regex",
                  "requests",
                  "scipy",
                  "six",
                  "sklearn",
                  "typing_extensions",
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spacy==2.1.3\n",
            "  Downloading spacy-2.1.3-cp37-cp37m-manylinux1_x86_64.whl (27.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 27.7 MB 17 kB/s \n",
            "\u001b[?25hCollecting requests<3.0.0,>=2.13.0\n",
            "  Using cached requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "Collecting numpy>=1.15.0\n",
            "  Using cached numpy-1.21.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "Collecting jsonschema<3.0.0,>=2.6.0\n",
            "  Downloading jsonschema-2.6.0-py2.py3-none-any.whl (39 kB)\n",
            "Collecting wasabi<1.1.0,>=0.2.0\n",
            "  Using cached wasabi-0.8.2-py3-none-any.whl (23 kB)\n",
            "Collecting blis<0.3.0,>=0.2.2\n",
            "  Downloading blis-0.2.4-cp37-cp37m-manylinux1_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 39.5 MB/s \n",
            "\u001b[?25hCollecting srsly<1.1.0,>=0.0.5\n",
            "  Downloading srsly-1.0.5-cp37-cp37m-manylinux2014_x86_64.whl (184 kB)\n",
            "\u001b[K     |████████████████████████████████| 184 kB 51.6 MB/s \n",
            "\u001b[?25hCollecting thinc<7.1.0,>=7.0.2\n",
            "  Downloading thinc-7.0.8-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 36.1 MB/s \n",
            "\u001b[?25hCollecting cymem<2.1.0,>=2.0.2\n",
            "  Using cached cymem-2.0.5-cp37-cp37m-manylinux2014_x86_64.whl (35 kB)\n",
            "Collecting murmurhash<1.1.0,>=0.28.0\n",
            "  Using cached murmurhash-1.0.5-cp37-cp37m-manylinux2014_x86_64.whl (20 kB)\n",
            "Collecting preshed<2.1.0,>=2.0.1\n",
            "  Downloading preshed-2.0.1-cp37-cp37m-manylinux1_x86_64.whl (82 kB)\n",
            "\u001b[K     |████████████████████████████████| 82 kB 281 kB/s \n",
            "\u001b[?25hCollecting plac<1.0.0,>=0.9.6\n",
            "  Downloading plac-0.9.6-py2.py3-none-any.whl (20 kB)\n",
            "Collecting certifi>=2017.4.17\n",
            "  Using cached certifi-2021.5.30-py2.py3-none-any.whl (145 kB)\n",
            "Collecting idna<4,>=2.5\n",
            "  Using cached idna-3.2-py3-none-any.whl (59 kB)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Using cached urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
            "Collecting charset-normalizer~=2.0.0\n",
            "  Using cached charset_normalizer-2.0.6-py3-none-any.whl (37 kB)\n",
            "Collecting tqdm<5.0.0,>=4.10.0\n",
            "  Using cached tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
            "Installing collected packages: numpy, cymem, wasabi, urllib3, tqdm, srsly, preshed, plac, murmurhash, idna, charset-normalizer, certifi, blis, thinc, requests, jsonschema, spacy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.2\n",
            "    Uninstalling numpy-1.21.2:\n",
            "      Successfully uninstalled numpy-1.21.2\n",
            "  Attempting uninstall: cymem\n",
            "    Found existing installation: cymem 2.0.5\n",
            "    Uninstalling cymem-2.0.5:\n",
            "      Successfully uninstalled cymem-2.0.5\n",
            "  Attempting uninstall: wasabi\n",
            "    Found existing installation: wasabi 0.8.2\n",
            "    Uninstalling wasabi-0.8.2:\n",
            "      Successfully uninstalled wasabi-0.8.2\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.7\n",
            "    Uninstalling urllib3-1.26.7:\n",
            "      Successfully uninstalled urllib3-1.26.7\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.62.3\n",
            "    Uninstalling tqdm-4.62.3:\n",
            "      Successfully uninstalled tqdm-4.62.3\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 2.4.1\n",
            "    Uninstalling srsly-2.4.1:\n",
            "      Successfully uninstalled srsly-2.4.1\n",
            "  Attempting uninstall: preshed\n",
            "    Found existing installation: preshed 3.0.5\n",
            "    Uninstalling preshed-3.0.5:\n",
            "      Successfully uninstalled preshed-3.0.5\n",
            "  Attempting uninstall: plac\n",
            "    Found existing installation: plac 1.1.3\n",
            "    Uninstalling plac-1.1.3:\n",
            "      Successfully uninstalled plac-1.1.3\n",
            "  Attempting uninstall: murmurhash\n",
            "    Found existing installation: murmurhash 1.0.5\n",
            "    Uninstalling murmurhash-1.0.5:\n",
            "      Successfully uninstalled murmurhash-1.0.5\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.2\n",
            "    Uninstalling idna-3.2:\n",
            "      Successfully uninstalled idna-3.2\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 2.0.6\n",
            "    Uninstalling charset-normalizer-2.0.6:\n",
            "      Successfully uninstalled charset-normalizer-2.0.6\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2021.5.30\n",
            "    Uninstalling certifi-2021.5.30:\n",
            "      Successfully uninstalled certifi-2021.5.30\n",
            "  Attempting uninstall: blis\n",
            "    Found existing installation: blis 0.7.4\n",
            "    Uninstalling blis-0.7.4:\n",
            "      Successfully uninstalled blis-0.7.4\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.0.10\n",
            "    Uninstalling thinc-8.0.10:\n",
            "      Successfully uninstalled thinc-8.0.10\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.26.0\n",
            "    Uninstalling requests-2.26.0:\n",
            "      Successfully uninstalled requests-2.26.0\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 2.6.0\n",
            "    Uninstalling jsonschema-2.6.0:\n",
            "      Successfully uninstalled jsonschema-2.6.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.1.3\n",
            "    Uninstalling spacy-3.1.3:\n",
            "      Successfully uninstalled spacy-3.1.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.6.0 requires numpy~=1.19.2, but you have numpy 1.21.2 which is incompatible.\n",
            "tensorflow 2.6.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "tensorflow 2.6.0 requires typing-extensions~=3.7.4, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "streamlit 1.0.0 requires click<8.0,>=7.0, but you have click 8.0.1 which is incompatible.\n",
            "nbclient 0.5.4 requires jupyter-client>=6.1.5, but you have jupyter-client 5.3.5 which is incompatible.\n",
            "google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.4.1 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.28.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "en-core-web-sm 2.2.5 requires spacy>=2.2.2, but you have spacy 2.1.3 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed blis-0.2.4 certifi-2021.5.30 charset-normalizer-2.0.6 cymem-2.0.5 idna-3.2 jsonschema-2.6.0 murmurhash-1.0.5 numpy-1.21.2 plac-0.9.6 preshed-2.0.1 requests-2.26.0 spacy-2.1.3 srsly-1.0.5 thinc-7.0.8 tqdm-4.62.3 urllib3-1.26.7 wasabi-0.8.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "idna",
                  "numpy",
                  "requests",
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en_core_web_sm==2.1.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz (11.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.1 MB 7.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: en-core-web-sm\n",
            "  Building wheel for en-core-web-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.1.0-py3-none-any.whl size=11074431 sha256=87a0d68b89ecf2b133f1cc0c85d3c61770df72f263371e486cd96f1cd77cec5e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4p5rsbwl/wheels/59/4f/8c/0dbaab09a776d1fa3740e9465078bfd903cc22f3985382b496\n",
            "Successfully built en-core-web-sm\n",
            "Installing collected packages: en-core-web-sm\n",
            "  Attempting uninstall: en-core-web-sm\n",
            "    Found existing installation: en-core-web-sm 2.2.5\n",
            "    Uninstalling en-core-web-sm-2.2.5:\n",
            "      Successfully uninstalled en-core-web-sm-2.2.5\n",
            "Successfully installed en-core-web-sm-2.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Collecting flashtext\n",
            "  Downloading flashtext-2.7.tar.gz (14 kB)\n",
            "Building wheels for collected packages: flashtext\n",
            "  Building wheel for flashtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flashtext: filename=flashtext-2.7-py2.py3-none-any.whl size=9310 sha256=e0d11634745afc9aaf80972207491998a855936fa6d1e82c593fe8441d77e20d\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/19/58/4e8fdd0009a7f89dbce3c18fff2e0d0fa201d5cdfd16f113b7\n",
            "Successfully built flashtext\n",
            "Installing collected packages: flashtext\n",
            "Successfully installed flashtext-2.7\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Collecting nltk\n",
            "  Downloading nltk-3.6.3-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 8.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from nltk) (2021.9.30)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.62.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (8.0.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from click->nltk) (4.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click->nltk) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click->nltk) (3.6.0)\n",
            "Installing collected packages: nltk\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed nltk-3.6.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nltk"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting neuralcoref\n",
            "  Downloading neuralcoref-4.0-cp37-cp37m-manylinux1_x86_64.whl (286 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 22.0 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 20 kB 26.0 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 30 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 40 kB 19.2 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 51 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 61 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |████████                        | 71 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 81 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 92 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 102 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 112 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 122 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 133 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 143 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 153 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 163 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 174 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 184 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 194 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 204 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 215 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 225 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 235 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 245 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 256 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 266 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 276 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 286 kB 7.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from neuralcoref) (1.21.2)\n",
            "Requirement already satisfied: spacy>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from neuralcoref) (2.1.3)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.18.54-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 53.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from neuralcoref) (2.26.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2021.5.30)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (1.26.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (3.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (2.0.5)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (0.2.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (1.0.5)\n",
            "Requirement already satisfied: jsonschema<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (2.6.0)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (7.0.8)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (2.0.1)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (0.9.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (0.8.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.7/dist-packages (from thinc<7.1.0,>=7.0.2->spacy>=2.1.0->neuralcoref) (4.62.3)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.4 MB/s \n",
            "\u001b[?25hCollecting botocore<1.22.0,>=1.21.54\n",
            "  Downloading botocore-1.21.54-py3-none-any.whl (8.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.0 MB 52.5 MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.54->boto3->neuralcoref) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.54->boto3->neuralcoref) (1.16.0)\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3, neuralcoref\n",
            "Successfully installed boto3-1.18.54 botocore-1.21.54 jmespath-0.10.0 neuralcoref-4.0 s3transfer-0.5.0\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 7.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n",
            "Collecting pywsd\n",
            "  Downloading pywsd-1.2.4.tar.gz (26.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.8 MB 26 kB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from pywsd) (3.6.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pywsd) (1.21.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pywsd) (1.1.5)\n",
            "Collecting wn\n",
            "  Downloading wn-0.8.0-py3-none-any.whl (66 kB)\n",
            "\u001b[K     |████████████████████████████████| 66 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pywsd) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->pywsd) (8.0.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from nltk->pywsd) (2021.9.30)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->pywsd) (1.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk->pywsd) (4.62.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from click->nltk->pywsd) (4.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click->nltk->pywsd) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click->nltk->pywsd) (3.6.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->pywsd) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pywsd) (2.8.2)\n",
            "Requirement already satisfied: requests~=2.25 in /usr/local/lib/python3.7/dist-packages (from wn->pywsd) (2.26.0)\n",
            "Requirement already satisfied: toml~=0.10 in /usr/local/lib/python3.7/dist-packages (from wn->pywsd) (0.10.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests~=2.25->wn->pywsd) (3.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests~=2.25->wn->pywsd) (2.0.6)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests~=2.25->wn->pywsd) (1.26.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests~=2.25->wn->pywsd) (2021.5.30)\n",
            "Building wheels for collected packages: pywsd\n",
            "  Building wheel for pywsd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pywsd: filename=pywsd-1.2.4-py3-none-any.whl size=26940436 sha256=aecaf55af37f950fbec5e9dc96aa87b4901f4f7043c2bd59d023f010a85a221a\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/67/c0/6e6fa8456d1374b393328368316c3b33844cb4043bd225bc66\n",
            "Successfully built pywsd\n",
            "Installing collected packages: wn, pywsd\n",
            "Successfully installed pywsd-1.2.4 wn-0.8.0\n",
            "Collecting wn==0.0.22\n",
            "  Downloading wn-0.0.22.tar.gz (31.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 31.5 MB 61 kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: wn\n",
            "  Building wheel for wn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wn: filename=wn-0.0.22-py3-none-any.whl size=31618484 sha256=79bd62deb60fcfad3458b8b00edfdea396df135173cf98e9493b3dbb4406df5e\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/0d/59/4b7902879d8cbad9bb73aaf0cc0a051edc1b18da983889c412\n",
            "Successfully built wn\n",
            "Installing collected packages: wn\n",
            "  Attempting uninstall: wn\n",
            "    Found existing installation: wn 0.8.0\n",
            "    Uninstalling wn-0.8.0:\n",
            "      Successfully uninstalled wn-0.8.0\n",
            "Successfully installed wn-0.0.22\n",
            "Collecting tika\n",
            "  Downloading tika-1.24.tar.gz (28 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tika) (58.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tika) (2.26.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (1.26.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (3.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (2021.5.30)\n",
            "Building wheels for collected packages: tika\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tika: filename=tika-1.24-py3-none-any.whl size=32891 sha256=fbd9948eccb14e48300bd9e1706495d06e70702936082bdcdc0aa2c8383c2809\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/2b/38/58ff05467a742e32f67f5d0de048fa046e764e2fbb25ac93f3\n",
            "Successfully built tika\n",
            "Installing collected packages: tika\n",
            "Successfully installed tika-1.24\n",
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.18.19-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 8.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.18.19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aV8-HNSuBKQp",
        "outputId": "7dafc86d-efa0-4e63-e219-ee4f65954dab"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('popular')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AGkcZA-cCEcA",
        "outputId": "b39dabc7-c278-40db-e814-3bf0219b01c9"
      },
      "source": [
        "!pip install summarizer\n",
        "!pip install git+https://github.com/boudinfl/pke.git\n",
        "!pip install neuralcoref\n",
        "!pip install flashtext\n",
        "!pip install PyMuPDF\n",
        "!pip install -U pywsd\n",
        "!pip install wn==0.0.22\n",
        "!pip install tika\n",
        "\n",
        "\n",
        "from summarizer import Summarizer\n",
        "from bs4 import BeautifulSoup\n",
        "import pprint\n",
        "import itertools\n",
        "import re\n",
        "import pke\n",
        "import pickle\n",
        "import spacy\n",
        "import string\n",
        "import os\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import neuralcoref\n",
        "from flashtext import KeywordProcessor\n",
        "from nltk.corpus import stopwords\n",
        "import requests\n",
        "import json\n",
        "import re\n",
        "import random\n",
        "import fitz\n",
        "from operator import itemgetter\n",
        "from pywsd.similarity import max_similarity\n",
        "from pywsd.lesk import adapted_lesk\n",
        "from pywsd.lesk import simple_lesk\n",
        "from pywsd.lesk import cosine_lesk\n",
        "from nltk.corpus import wordnet as wn\n",
        "from tika import parser\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "model = Summarizer()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting summarizer\n",
            "  Downloading summarizer-0.0.7.tar.gz (280 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 22.4 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 30 kB 29.8 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 40 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 51 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 61 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 71 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 81 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 92 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 102 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 112 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 122 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 133 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 143 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 153 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 163 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 174 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 184 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 194 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 204 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 215 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 225 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 235 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 245 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 256 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 266 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 276 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 280 kB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from summarizer) (3.6.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->summarizer) (1.0.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from nltk->summarizer) (2021.9.30)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk->summarizer) (4.62.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->summarizer) (8.0.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from click->nltk->summarizer) (4.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click->nltk->summarizer) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click->nltk->summarizer) (3.6.0)\n",
            "Building wheels for collected packages: summarizer\n",
            "  Building wheel for summarizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for summarizer: filename=summarizer-0.0.7-py2.py3-none-any.whl size=284225 sha256=7439c81dca75cc601c9e18ae5ffe8ffc39b9fcce81dfc233cd0f3bb40aee38f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/f4/31/e1/87a3a8fe942ba73a249d2df55a2df498a12dacf6bc62a43446\n",
            "Successfully built summarizer\n",
            "Installing collected packages: summarizer\n",
            "Successfully installed summarizer-0.0.7\n",
            "Collecting git+https://github.com/boudinfl/pke.git\n",
            "  Cloning https://github.com/boudinfl/pke.git to /tmp/pip-req-build-2ttkf_x7\n",
            "  Running command git clone -q https://github.com/boudinfl/pke.git /tmp/pip-req-build-2ttkf_x7\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from pke==1.8.1) (3.6.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from pke==1.8.1) (2.6.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pke==1.8.1) (1.21.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pke==1.8.1) (1.7.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (from pke==1.8.1) (2.1.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pke==1.8.1) (1.16.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pke==1.8.1) (0.0)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.7/dist-packages (from pke==1.8.1) (1.3.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pke==1.8.1) (0.16.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pke==1.8.1) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->pke==1.8.1) (8.0.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from nltk->pke==1.8.1) (2021.9.30)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk->pke==1.8.1) (4.62.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from click->nltk->pke==1.8.1) (4.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click->nltk->pke==1.8.1) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click->nltk->pke==1.8.1) (3.6.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->pke==1.8.1) (1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->pke==1.8.1) (3.0.0)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (7.0.8)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (2.0.5)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (0.2.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (1.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (2.26.0)\n",
            "Requirement already satisfied: jsonschema<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (2.6.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (0.8.2)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (2.0.1)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (0.9.6)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (2021.5.30)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (1.26.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (3.2)\n",
            "Requirement already satisfied: neuralcoref in /usr/local/lib/python3.7/dist-packages (4.0)\n",
            "Requirement already satisfied: spacy>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from neuralcoref) (2.1.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from neuralcoref) (1.21.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from neuralcoref) (2.26.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from neuralcoref) (1.18.54)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2021.5.30)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (3.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (1.26.7)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (7.0.8)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (0.8.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (2.0.5)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (2.0.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (1.0.5)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (0.9.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (1.0.5)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (0.2.4)\n",
            "Requirement already satisfied: jsonschema<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (2.6.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.7/dist-packages (from thinc<7.1.0,>=7.0.2->spacy>=2.1.0->neuralcoref) (4.62.3)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->neuralcoref) (0.5.0)\n",
            "Requirement already satisfied: botocore<1.22.0,>=1.21.54 in /usr/local/lib/python3.7/dist-packages (from boto3->neuralcoref) (1.21.54)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->neuralcoref) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.54->boto3->neuralcoref) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.54->boto3->neuralcoref) (1.16.0)\n",
            "Requirement already satisfied: flashtext in /usr/local/lib/python3.7/dist-packages (2.7)\n",
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.7/dist-packages (1.18.19)\n",
            "Requirement already satisfied: pywsd in /usr/local/lib/python3.7/dist-packages (1.2.4)\n",
            "Requirement already satisfied: wn in /usr/local/lib/python3.7/dist-packages (from pywsd) (0.0.22)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pywsd) (1.21.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from pywsd) (3.6.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pywsd) (1.1.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pywsd) (1.16.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->pywsd) (1.0.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from nltk->pywsd) (2021.9.30)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk->pywsd) (4.62.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->pywsd) (8.0.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from click->nltk->pywsd) (4.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click->nltk->pywsd) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click->nltk->pywsd) (3.10.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pywsd) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->pywsd) (2018.9)\n",
            "Requirement already satisfied: wn==0.0.22 in /usr/local/lib/python3.7/dist-packages (0.0.22)\n",
            "Requirement already satisfied: tika in /usr/local/lib/python3.7/dist-packages (1.24)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tika) (58.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tika) (2.26.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (3.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (1.26.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (2021.5.30)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-bca40f8ce17e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpke\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pke/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpke\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMinimalCoreNLPReader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRawTextReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpke\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLoadFile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m from pke.utils import (load_document_frequency_file, compute_document_frequency,\n\u001b[0m\u001b[1;32m      7\u001b[0m                        \u001b[0mtrain_supervised_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_references\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                        \u001b[0mcompute_lda_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_document_as_bos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pke/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLatentDirichletAllocation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_pca\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_incremental_pca\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIncrementalPCA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_kernel_pca\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKernelPCA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_sparse_pca\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparsePCA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMiniBatchSparsePCA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_truncated_svd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTruncatedSVD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_kernel_pca.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_arpack\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_init_arpack_v0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextmath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msvd_flip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_randomized_eigsh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_check_psd_eigenvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name '_randomized_eigsh' from 'sklearn.utils.extmath' (/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ4f23CwHbfh"
      },
      "source": [
        "EXTRACTING KEYWORDS\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoocGaEO3MRn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eb16c76-ed30-4cc4-bb07-5163e2ce2c74"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2tSF8tT4KzD",
        "outputId": "3a55384f-2d47-4bf8-9ae3-5f571eec4865"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eop_L4j8EkyW"
      },
      "source": [
        "def get_nouns_multipartite(text):\n",
        "    out=[]\n",
        "\n",
        "    extractor = pke.unsupervised.MultipartiteRank()\n",
        "    extractor.load_document(input=text)\n",
        "    #    not contain punctuation marks or stopwords as candidates.\n",
        "    pos = {'PROPN'}\n",
        "    #pos = {'VERB', 'ADJ', 'NOUN'}\n",
        "    stoplist = list(string.punctuation)\n",
        "    stoplist += ['-lrb-', '-rrb-', '-lcb-', '-rcb-', '-lsb-', '-rsb-']\n",
        "    stoplist += stopwords.words('english')\n",
        "    extractor.candidate_selection(pos=pos, stoplist=stoplist)\n",
        "    # 4. build the Multipartite graph and rank candidates using random walk,\n",
        "    #    alpha controls the weight adjustment mechanism, see TopicRank for\n",
        "    #    threshold/method parameters.\n",
        "    extractor.candidate_weighting(alpha=1.1,\n",
        "                                  threshold=0.75,\n",
        "                                  method='average') \n",
        "    keyphrases = extractor.get_n_best(n=50)\n",
        "\n",
        "    for key in keyphrases:\n",
        "        out.append(key[0])\n",
        "\n",
        "    return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itQJWJ5FH3Qh"
      },
      "source": [
        "def tokenize_sentences(text):\n",
        "    sentences = [sent_tokenize(text)]\n",
        "    sentences = [y for x in sentences for y in x]\n",
        "    # Remove any short sentences less than 20 letters.\n",
        "    sentences = [sentence.strip() for sentence in sentences if len(sentence) > 20]\n",
        "    return sentences\n",
        "\n",
        "def get_sentences_for_keyword(keywords, sentences):\n",
        "    keyword_processor = KeywordProcessor()\n",
        "    keyword_sentences = {}\n",
        "    temp = []\n",
        "    for word in keywords:\n",
        "        keyword_sentences[word] = []\n",
        "        keyword_processor.add_keyword(word)\n",
        "    for sentence in sentences:\n",
        "        keywords_found = keyword_processor.extract_keywords(sentence)\n",
        "        for key in keywords_found:\n",
        "            keyword_sentences[key].append(sentence)\n",
        "\n",
        "    for key in keyword_sentences.keys():\n",
        "        values = keyword_sentences[key]\n",
        "        values = sorted(values, key=len, reverse=True)\n",
        "        keyword_sentences[key] = values\n",
        "        if len(values)==0:\n",
        "          temp.append(key)\n",
        "        \n",
        "    for i in temp:\n",
        "        del(keyword_sentences[i])\n",
        "  \n",
        "    return keyword_sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OemjOIGLH-XO"
      },
      "source": [
        "# Distractors from Wordnet\n",
        "def get_distractors_wordnet(syn,word):\n",
        "    distractors=[]\n",
        "    word= word.lower()\n",
        "    orig_word = word\n",
        "    if len(word.split())>0:\n",
        "        word = word.replace(\" \",\"_\")\n",
        "    hypernym = syn.hypernyms()\n",
        "    if len(hypernym) == 0: \n",
        "        return distractors\n",
        "    for item in hypernym[0].hyponyms():\n",
        "        name = item.lemmas()[0].name()\n",
        "        #print (\"name \",name, \" word\",orig_word)\n",
        "        if name == orig_word:\n",
        "            continue\n",
        "        name = name.replace(\"_\",\" \")\n",
        "        name = \" \".join(w.capitalize() for w in name.split())\n",
        "        if name is not None and name not in distractors:\n",
        "            distractors.append(name)\n",
        "    return distractors\n",
        "\n",
        "def get_wordsense(sent,word):\n",
        "    word= word.lower()\n",
        "    \n",
        "    if len(word.split())>0:\n",
        "        word = word.replace(\" \",\"_\")\n",
        "      \n",
        "    synsets = wn.synsets(word,'n')\n",
        "\n",
        "    if synsets:\n",
        "        wup = max_similarity(sent, word, 'wup', pos='n')\n",
        "        adapted_lesk_output =  adapted_lesk(sent, word, pos='n')\n",
        "        lowest_index = min (synsets.index(wup),synsets.index(adapted_lesk_output))\n",
        "        return synsets[lowest_index]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Distractors from http://conceptnet.io/\n",
        "def get_distractors_conceptnet(word):\n",
        "    word = word.lower()\n",
        "    original_word= word\n",
        "    if (len(word.split())>0):\n",
        "        word = word.replace(\" \",\"_\")\n",
        "    distractor_list = [] \n",
        "    url = \"http://api.conceptnet.io/query?node=/c/en/%s/n&rel=/r/PartOf&start=/c/en/%s&limit=5\"%(word,word)\n",
        "    obj = requests.get(url).json()\n",
        "\n",
        "    for edge in obj['edges']:\n",
        "        link = edge['end']['term'] \n",
        "\n",
        "        url2 = \"http://api.conceptnet.io/query?node=%s&rel=/r/PartOf&end=%s&limit=10\"%(link,link)\n",
        "        obj2 = requests.get(url2).json()\n",
        "        for edge in obj2['edges']:\n",
        "            word2 = edge['start']['label']\n",
        "            if word2 not in distractor_list and original_word.lower() not in word2.lower():\n",
        "                distractor_list.append(word2)\n",
        "                   \n",
        "    return distractor_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0DO2hFBIXGQ"
      },
      "source": [
        "# Given an index eg: 8 and a list ['Scientists ', 'know ', 'many ', 'things ', 'about ', 'the ', 'Sun', '. ', 'They ', 'know ', 'how ', 'old ', 'it ', 'is', '. ', 'The ', 'Sun ', 'is ', 'more ', 'than ', '4½ ', 'billion ', 'years ', 'old', '. ', 'It ', 'is ', 'also ', 'a ', 'star', '. ', 'They ', 'also ', 'know ', 'the ', 'Sun', '’s ', 'size', '.']\n",
        "# Retrieve the sentence corresponding to that index as a list. Eg: ['They ', 'know ', 'how ', 'old ', 'it ', 'is', '. '] \n",
        "def get_sentence_for_index(index,resolved_list):\n",
        "    end_of_sentence_punctuation = ['.','!','?']\n",
        "    beginning_index = index\n",
        "    ending_index = index\n",
        "    while (beginning_index>=0):\n",
        "        val = resolved_list[beginning_index].strip()\n",
        "        if (val in end_of_sentence_punctuation):\n",
        "            break\n",
        "        else:\n",
        "            beginning_index = beginning_index -1\n",
        "    while (ending_index<=(len(resolved_list)-1)):\n",
        "        val = resolved_list[ending_index].strip()\n",
        "        if (val in end_of_sentence_punctuation):\n",
        "            break\n",
        "        else:\n",
        "            ending_index = ending_index +1\n",
        "    return resolved_list[beginning_index+1:ending_index+1],beginning_index+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWHj7rXCIZFK"
      },
      "source": [
        "def get_resolved(doc, clusters):\n",
        "    ''' Return a list of utterrances text where the coref are resolved to the most representative mention'''\n",
        "    resolved = list(tok.text_with_ws for tok in doc)\n",
        "    questions =[]\n",
        "    for cluster in clusters:\n",
        "        for coref in cluster:\n",
        "            coref_text = coref.text.lower()\n",
        "            cluster_main_text = cluster.main.text.lower()\n",
        "            if len(coref_text.split())==1 and coref_text != cluster_main_text and coref_text in pronoun_list:\n",
        "                get_sentence,start_index = get_sentence_for_index(coref.start,resolved)\n",
        "                get_sentence_string = ''.join(get_sentence).lower()\n",
        "                cluster_main_string = ' '.join(cluster_main_text.strip().split())\n",
        "                if (cluster_main_string not in get_sentence_string):\n",
        "                    resolved[coref.start] = cluster.main.text + doc[coref.end-1].whitespace_\n",
        "                    if start_index == coref.start:\n",
        "                        resolved[coref.start] = resolved[coref.start].capitalize() \n",
        "                    final_sentence = ''.join(get_sentence)\n",
        "                    # Leave out very short sentences to frame questions.\n",
        "                    \n",
        "                    # if len(final_sentence)>20:\n",
        "                    #     questions.append([final_sentence,coref.text,resolved[coref.start]])\n",
        "\n",
        "                    questions.append([final_sentence,coref.text,resolved[coref.start]])\n",
        "\n",
        "                \n",
        "\n",
        "    return ''.join(resolved),questions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHqtUrKYIooQ"
      },
      "source": [
        "MCQ FROM INSHORTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKGQxyzwIggm"
      },
      "source": [
        "def generate_mcqs_inshorts(keyword_sentence_mapping,temp_file,index_counter):\n",
        "\n",
        "  key_distractor_list = {}\n",
        "\n",
        "  for keyword in keyword_sentence_mapping:\n",
        "\n",
        "      try:\n",
        "        wordsense = get_wordsense(keyword_sentence_mapping[keyword][0],keyword)\n",
        "      except:\n",
        "        wordsense = False\n",
        "\n",
        "      if wordsense:\n",
        "          distractors = get_distractors_wordnet(wordsense,keyword)\n",
        "          if len(distractors) ==0:\n",
        "              distractors = get_distractors_conceptnet(keyword)\n",
        "          if len(distractors) != 0:\n",
        "              key_distractor_list[keyword] = distractors\n",
        "      else:\n",
        "          distractors = get_distractors_conceptnet(keyword)\n",
        "          if len(distractors) != 0:\n",
        "              key_distractor_list[keyword] = distractors\n",
        "\n",
        "\n",
        "  file5 = open(temp_file, \"a+\")\n",
        "\n",
        "  total_sentence = list()\n",
        "\n",
        "  for each in key_distractor_list:\n",
        "\n",
        "      sentence = keyword_sentence_mapping[each][0]\n",
        "\n",
        "      if(sentence not in total_sentence):\n",
        "        total_sentence.append(sentence)\n",
        "        pattern = re.compile(each, re.IGNORECASE)\n",
        "        output = pattern.sub( \" _______ \", sentence)\n",
        "\n",
        "        temp =str(index_counter)+\")\"+output+\"\\n\"\n",
        "        print(temp)\n",
        "        file5.write(temp)\n",
        "    \n",
        "        choices = [each.capitalize()] + key_distractor_list[each]\n",
        "        top4choices = choices[:4]\n",
        "        random.shuffle(top4choices)\n",
        "        optionchoices = ['a','b','c','d']\n",
        "        for idx,choice in enumerate(top4choices):\n",
        "\n",
        "          temp = \"\\t\"+optionchoices[idx]+\")\"+\" \"+choice +\"\\n\"\n",
        "          print(temp)\n",
        "          file5.write(temp)\n",
        "\n",
        "        temp = \"Answer:\"+each+\"\\n\"\n",
        "        file5.write(temp)\n",
        "        print(temp)\n",
        "      \n",
        "        index_counter = index_counter + 1\n",
        "\n",
        "  file5.close()\n",
        "\n",
        "  return index_counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCyU0fcOUHmD"
      },
      "source": [
        "FOR TOTAL QUESTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FncbxzUCim68",
        "outputId": "be539e37-92d5-45cc-f0c5-2bb795c0084a"
      },
      "source": [
        "!pip install sumy\n",
        "!pip install streamlit\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('popular')\n",
        "\n",
        "from sumy.parsers.html import HtmlParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.lsa import LsaSummarizer as Summarizer\n",
        "from sumy.nlp.stemmers import Stemmer\n",
        "from sumy.utils import get_stop_words\n",
        "import requests\n",
        "def summarize_html(url: str, sentences_count: int, language: str = 'english') -> str:\n",
        "    \"\"\"\n",
        "    Summarizes text from URL\n",
        "    \n",
        "    Inputs\n",
        "    ----------\n",
        "    url: URL for full text\n",
        "    sentences_count: specifies max number of sentences for return value\n",
        "    language: specifies language of text\n",
        "    \n",
        "    Return\n",
        "    ----------\n",
        "    summary of text from URL\n",
        "    \"\"\"\n",
        "    parser = HtmlParser.from_url(url, Tokenizer(language))\n",
        "    stemmer = Stemmer(language)\n",
        "    summarizer = Summarizer(stemmer)\n",
        "    summarizer.stop_words = get_stop_words(language)\n",
        "\n",
        "    summary = ''\n",
        "    for sentence in summarizer(parser.document, sentences_count):\n",
        "        if not summary:\n",
        "            summary += str(sentence)\n",
        "        else:\n",
        "            summary += ' ' + str(sentence)\n",
        "\n",
        "    return summary\n",
        "    \n",
        "url = 'http://www.inshorts.com/en/read/'\n",
        "summary = summarize_html(url, 20)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sumy in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: breadability>=0.1.20 in /usr/local/lib/python3.7/dist-packages (from sumy) (0.1.20)\n",
            "Requirement already satisfied: nltk>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from sumy) (3.2.5)\n",
            "Requirement already satisfied: pycountry>=18.2.23 in /usr/local/lib/python3.7/dist-packages (from sumy) (20.7.3)\n",
            "Requirement already satisfied: docopt<0.7,>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from sumy) (0.6.2)\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from sumy) (2.23.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from breadability>=0.1.20->sumy) (3.0.4)\n",
            "Requirement already satisfied: lxml>=2.0 in /usr/local/lib/python3.7/dist-packages (from breadability>=0.1.20->sumy) (4.2.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=3.0.2->sumy) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.7.0->sumy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.7.0->sumy) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.7.0->sumy) (2.10)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.7/dist-packages (1.0.0)\n",
            "Requirement already satisfied: pydeck>=0.1.dev5 in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.7.0)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.2.4)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.5.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.23.0)\n",
            "Requirement already satisfied: validators in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.18.2)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: pandas>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.8.2)\n",
            "Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (5.1.1)\n",
            "Requirement already satisfied: blinker in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.19.5)\n",
            "Requirement already satisfied: protobuf!=3.11,>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.17.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from streamlit) (21.0)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.8.1)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from streamlit) (21.2.0)\n",
            "Requirement already satisfied: watchdog in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.1.6)\n",
            "Requirement already satisfied: click<8.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.1.2)\n",
            "Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.1.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19 in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.1.24)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.1.2)\n",
            "Requirement already satisfied: base58 in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.1.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (2.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (2.11.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (0.11.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (0.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from gitpython!=3.1.19->streamlit) (4.0.7)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from gitpython!=3.1.19->streamlit) (3.7.4.3)\n",
            "Requirement already satisfied: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit) (4.0.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.0->streamlit) (2018.9)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf!=3.11,>=3.6.0->streamlit) (1.15.0)\n",
            "Requirement already satisfied: ipykernel>=5.1.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (6.4.1)\n",
            "Requirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (5.1.0)\n",
            "Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (7.6.5)\n",
            "Requirement already satisfied: jupyter-client<8.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (5.3.5)\n",
            "Requirement already satisfied: ipython<8.0,>=7.23.1 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (7.28.0)\n",
            "Requirement already satisfied: importlib-metadata<5 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.8.1)\n",
            "Requirement already satisfied: argcomplete>=1.12.3 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (1.12.3)\n",
            "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (1.0.0)\n",
            "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.1.3)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (3.6.0)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (3.0.20)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.7.5)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.18.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (57.4.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.8.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.5.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.0.2)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.1.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->altair>=3.2.0->streamlit) (2.0.1)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<8.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.8.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<8.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (22.3.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.2.5)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.3.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.8.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.6.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.12.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.7.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.5.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (4.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->streamlit) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (3.0.4)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGS1mhcsivph"
      },
      "source": [
        "content_list = ['sports','national','business','world','politics','technology','startup','entertainment','miscellaneous','hatke','science','automobile']\n",
        "\n",
        "topic_dict = dict()\n",
        "for content in content_list:\n",
        "\n",
        "  temp = list()\n",
        "\n",
        "  url = 'http://www.inshorts.com/en/read/'\n",
        "  summary = summarize_html(url, 20)\n",
        "\n",
        "  for i in summary:\n",
        "    temp.append(summary) \n",
        "\n",
        "  topic_dict[content] = temp   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIvLzGBe_2tA"
      },
      "source": [
        " topic_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "Gj_iYgZdUfMm",
        "outputId": "9bce5927-cdcc-417f-d63e-1ab8ac1382cf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "index_counter = 1\n",
        "\n",
        "temp_file = \"/content/gdrive/My Drive/inshorts_oct.txt\"\n",
        "\n",
        "\n",
        "for i in topic_dict:\n",
        "  \n",
        "  file = open(temp_file, \"a+\")\n",
        "  temp = \"\\n\"+ i +\"\\n\"\n",
        "  print(temp)\n",
        "  file.write(temp)\n",
        "  file.close()\n",
        "\n",
        "  for j in topic_dict[i]:\n",
        "\n",
        "    full_text = j\n",
        "    keywords = get_nouns_multipartite(full_text) \n",
        "    sentences = tokenize_sentences(full_text)\n",
        "    keyword_sentence_mapping = get_sentences_for_keyword(keywords, sentences)\n",
        "\n",
        "    index_counter = generate_mcqs_inshorts(keyword_sentence_mapping,temp_file,index_counter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-1d2c4f5a8f7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtopic_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"a+\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 107] Transport endpoint is not connected: '/content/gdrive/My Drive/inshorts_oct.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUJTcrpgw6eY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}